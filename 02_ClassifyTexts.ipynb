{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Pipeline for classifiying texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier expects input text files of containing:  \n",
    "`sentence id[tab]sentence[tab]None`  \n",
    "etc. \n",
    "\n",
    "The sentences should be tokenized, and tokens should be separated by a space.\n",
    "\n",
    "It is best to have a single file for each text for which labels should be predicted.\n",
    "\n",
    "The text files should be put together in a single directory.\n",
    "\n",
    "Use notebook [01_CreateDataForPrediction](01_CreateDataForPrediction.ipynb) to generate data in the correct format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Annotation\n",
    "\n",
    "# path to the input data\n",
    "data_dir = '/home/jvdzwaan/data/embem/txt/annotation-for_prediction-normalized/'\n",
    "\n",
    "# specify the path where output should be written\n",
    "out_dir = '/home/jvdzwaan/data/embem/txt/annotation-predicted-heem-normalized/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Corpus big\n",
    "\n",
    "# path to the input data\n",
    "data_dir = '/home/jvdzwaan/data/embem/txt/corpus_big-for_prediction-normalized/'\n",
    "\n",
    "# specify the path where output should be written\n",
    "out_dir = '/home/jvdzwaan/data/embem/txt/corpus_big-predicted-heem-normalized/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ceneton data\n",
    "\n",
    "# path to the input data\n",
    "data_dir = '/home/jvdzwaan/data/embem/txt/ceneton-for_prediction-normalized/'\n",
    "\n",
    "# specify the path where output should be written\n",
    "out_dir = '/home/jvdzwaan/data/embem/txt/ceneton-predicted-heem-normalized/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# EDBO data\n",
    "\n",
    "# path to the input data\n",
    "data_dir = '/home/jvdzwaan/data/embem/txt/edbo-for_prediction-normalized/'\n",
    "\n",
    "# specify the path where output should be written\n",
    "out_dir = '/home/jvdzwaan/data/embem/txt/edbo-predicted-heem-normalized/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "# classifier file\n",
    "classifier = '/home/jvdzwaan/data/classifier/classifier.pkl'\n",
    "\n",
    "# train file\n",
    "train_file = '/home/jvdzwaan/data/embem_ml/multilabel-normalized/all.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1 of 29) vond001gysb04.txt\n",
      "(2 of 29) ross006zing01.txt\n",
      "(3 of 29) huyd001achi01.txt\n",
      "(4 of 29) hoof001gran01.txt\n",
      "(5 of 29) stee033adag01.txt\n",
      "(6 of 29) rivi001jeug01.txt\n",
      "(7 of 29) fres003pefr01.txt\n",
      "(8 of 29) bidl001nede01.txt\n",
      "(9 of 29) hare003agon01.txt\n",
      "(10 of 29) alew001puit01.txt\n",
      "(11 of 29) hoof001achi01.txt\n",
      "(12 of 29) lijn002vlug01.txt\n",
      "(13 of 29) bred001moor01.txt\n",
      "(14 of 29) stee033tham01.txt\n",
      "(15 of 29) alew001besl01.txt\n",
      "(16 of 29) vinc001pefr02.txt\n",
      "(17 of 29) bren001scha01.txt\n",
      "(18 of 29) lang020chph01.txt\n",
      "(19 of 29) bren001goud01.txt\n",
      "(20 of 29) meij001verl01.txt\n",
      "(21 of 29) vond001jose05.txt\n",
      "(22 of 29) vond001pala01.txt\n",
      "(23 of 29) rivi001vero01.txt\n",
      "(24 of 29) pels001verw02.txt\n",
      "(25 of 29) focq001mini02.txt\n",
      "(26 of 29) noms001mich01.txt\n",
      "(27 of 29) weye002holl01.txt\n",
      "(28 of 29) vos_002kluc01.txt\n",
      "(29 of 29) ling001ontd01.txt\n"
     ]
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "import codecs\n",
    "from utils import get_data, load_data\n",
    "\n",
    "# load classifier\n",
    "clf = joblib.load(classifier)\n",
    "\n",
    "text_files = [fi for fi in os.listdir(data_dir) if fi.endswith('.txt')]\n",
    "for i, text_file in enumerate(text_files):\n",
    "    in_file = os.path.join(data_dir, text_file)\n",
    "    print('({} of {}) {}'.format(i+1, len(text_files), text_file))\n",
    "\n",
    "    # load data\n",
    "    X_train, X_data, Y_train, Y_data, classes_ = get_data(train_file, in_file)\n",
    "\n",
    "    # classifiy\n",
    "    pred = clf.predict(X_data)\n",
    "\n",
    "    # save results\n",
    "    out_file = os.path.join(out_dir, text_file)\n",
    "\n",
    "    X_data_with_ids, Y_data = load_data(in_file)\n",
    "\n",
    "    with codecs.open(out_file, 'wb', 'utf8') as f:\n",
    "        for x, y in zip(X_data_with_ids, pred):\n",
    "            f.write(u'{}\\t{}\\n'.format(x.decode('utf8'),\n",
    "                                       '_'.join(classes_[y]) or 'None'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1 of 29) vond001gysb04.txt\n",
      "(2 of 29) ross006zing01.txt\n",
      "(3 of 29) huyd001achi01.txt\n",
      "(4 of 29) hoof001gran01.txt\n",
      "(5 of 29) stee033adag01.txt\n",
      "(6 of 29) rivi001jeug01.txt\n",
      "(7 of 29) fres003pefr01.txt\n",
      "(8 of 29) bidl001nede01.txt\n",
      "(9 of 29) hare003agon01.txt\n",
      "(10 of 29) alew001puit01.txt\n",
      "(11 of 29) hoof001achi01.txt\n",
      "(12 of 29) lijn002vlug01.txt\n",
      "(13 of 29) bred001moor01.txt\n",
      "(14 of 29) stee033tham01.txt\n",
      "(15 of 29) alew001besl01.txt\n",
      "(16 of 29) vinc001pefr02.txt\n",
      "(17 of 29) bren001scha01.txt\n",
      "(18 of 29) lang020chph01.txt\n",
      "(19 of 29) bren001goud01.txt\n",
      "(20 of 29) meij001verl01.txt\n",
      "(21 of 29) vond001jose05.txt\n",
      "(22 of 29) vond001pala01.txt\n",
      "(23 of 29) rivi001vero01.txt\n",
      "(24 of 29) pels001verw02.txt\n",
      "(25 of 29) focq001mini02.txt\n",
      "(26 of 29) noms001mich01.txt\n",
      "(27 of 29) weye002holl01.txt\n",
      "(28 of 29) vos_002kluc01.txt\n",
      "(29 of 29) ling001ontd01.txt\n"
     ]
    }
   ],
   "source": [
    "# make unnormalized version of predicted labels (needed before expanding body part labels)\n",
    "\n",
    "%run merge_data_and_labels.py /home/jvdzwaan/data/embem/txt/annotation-predicted-heem-normalized/ /home/jvdzwaan/data/embem/txt/annotation-for_prediction/ /home/jvdzwaan/data/embem/txt/annotation-predicted-heem\n",
    "#%run merge_data_and_labels.py /home/jvdzwaan/data/embem/txt/corpus_big-predicted-heem-normalized/ /home/jvdzwaan/data/embem/txt/corpus_big-for_prediction/ /home/jvdzwaan/data/embem/txt/corpus_big-predicted-heem\n",
    "#%run merge_data_and_labels.py /home/jvdzwaan/data/embem/txt/ceneton-predicted-heem-normalized/ /home/jvdzwaan/data/embem/txt/ceneton-for_prediction/ /home/jvdzwaan/data/embem/txt/ceneton-predicted-heem\n",
    "#%run merge_data_and_labels.py /home/jvdzwaan/data/embem/txt/edbo-predicted-heem-normalized/ /home/jvdzwaan/data/embem/txt/edbo-for_prediction/ /home/jvdzwaan/data/embem/txt/edbo-predicted-heem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ignored: rose-kaken (cheeks)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "classify_body_parts.py:34: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  if w in word2cat.keys():\n"
     ]
    }
   ],
   "source": [
    "# Expand body parts\n",
    "\n",
    "%run classify_body_parts.py /home/jvdzwaan/data/embem/dict/body_part_mapping.json /home/jvdzwaan/data/embem/txt/annotation-predicted-heem/ /home/jvdzwaan/data/embem/txt/annotation-predicted-heem-expanded_body_parts  /home/jvdzwaan/data/embem/dict/annotation_heem_expanded_body_parts.csv\n",
    "#%run classify_body_parts.py /home/jvdzwaan/data/embem/dict/body_part_mapping.json /home/jvdzwaan/data/embem/txt/corpus_big-predicted-heem/ /home/jvdzwaan/data/embem/txt/corpus_big-predicted-heem-expanded_body_parts  /home/jvdzwaan/data/embem/dict/corpus_big_heem_expanded_body_parts.csv\n",
    "#%run classify_body_parts.py /home/jvdzwaan/data/embem/dict/body_part_mapping.json /home/jvdzwaan/data/embem/txt/ceneton-predicted-heem/ /home/jvdzwaan/data/embem/txt/ceneton-predicted-heem-expanded_body_parts  /home/jvdzwaan/data/embem/dict/ceneton_heem_expanded_body_parts.csv\n",
    "#%run classify_body_parts.py /home/jvdzwaan/data/embem/dict/body_part_mapping.json /home/jvdzwaan/data/embem/txt/edbo-predicted-heem/ /home/jvdzwaan/data/embem/txt/edbo-predicted-heem-expanded_body_parts  /home/jvdzwaan/data/embem/dict/edbo_heem_expanded_body_parts.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The next step is to look at the results!\n",
    "\n",
    "_To do: pipeline for showing/visualizing results_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
